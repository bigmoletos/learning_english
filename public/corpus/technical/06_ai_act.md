# The EU Artificial Intelligence Act: Comprehensive Overview

**Level: B2-C1**  
**Domain: AI Regulation & Policy**  
**Reading time: 7 minutes**

## Introduction

The European Union's Artificial Intelligence Act represents the world's first comprehensive regulatory framework for artificial intelligence. Adopted in 2024, the AI Act establishes a risk-based approach to regulating AI systems, balancing innovation encouragement with protection of fundamental rights. Understanding this legislation is crucial for any organization developing or deploying AI systems in the European market.

## Risk-Based Classification

### Minimal Risk AI

The majority of AI systems fall into this category, including spam filters, video games with AI opponents, and inventory management systems. These systems face no specific regulatory obligations beyond existing laws, allowing innovation to proceed freely for low-risk applications.

### Limited Risk AI

Systems like chatbots and deepfakes have limited risk but must meet transparency requirements. Users must be informed when interacting with AI systems, and generated content must be clearly labeled as artificial. This addresses concerns about deception while imposing minimal compliance burdens.

### High-Risk AI

High-risk AI systems undergo the most scrutiny. These include AI used in:

- **Critical infrastructure**: Systems managing water, electricity, or transportation
- **Education and vocational training**: AI determining educational opportunities
- **Employment**: Recruitment tools, performance evaluation systems
- **Essential services**: Credit scoring, emergency response prioritization
- **Law enforcement**: Biometric identification, crime prediction algorithms
- **Migration and border control**: Visa application assessors, deportation risk evaluations
- **Justice**: AI assisting in judicial interpretation or application of law

High-risk systems must comply with stringent requirements including risk management systems, high-quality training data, detailed documentation, human oversight, and robustness standards.

### Unacceptable Risk AI

Certain AI applications are completely prohibited, including:

- Social scoring systems by governments
- Real-time remote biometric identification in public spaces (with narrow exceptions)
- AI exploiting vulnerabilities of specific groups
- Subliminal manipulation techniques

## Requirements for High-Risk Systems

### Risk Management

Providers must establish, implement, and maintain a risk management system throughout the AI system's lifecycle. This includes identifying known and foreseeable risks, evaluating risks arising from reasonably foreseeable misuse, and implementing appropriate risk mitigation measures.

### Data Governance

Training, validation, and testing datasets must be relevant, representative, and free from errors to the extent possible. Special attention must be paid to biases that could lead to discrimination. Organizations must document data provenance, quality checks, and any preprocessing steps.

### Technical Documentation

Comprehensive technical documentation must demonstrate compliance with AI Act requirements. This includes system design and development process, system capabilities and limitations, algorithms and data used, training methodology, testing results, and human oversight measures.

### Record-Keeping

High-risk AI systems must maintain automatic logging capabilities, recording system operations to enable traceability and post-market monitoring. Logs must be kept for appropriate periods considering the AI system's intended purpose and legal obligations.

### Transparency and Information

Users must receive clear, comprehensive information about the AI system's capabilities, limitations, and level of accuracy. Instructions for use must be written in language understandable to users and must include expected lifespan, maintenance procedures, and measures for human oversight.

### Human Oversight

High-risk systems must be designed to allow effective oversight by natural persons. Human oversight aims to prevent or minimize risks to health, safety, or fundamental rights that may emerge when a system is used. This includes the ability to:

- Fully understand system capacities and limitations
- Remain aware of automation bias
- Interpret system outputs correctly
- Intervene or interrupt system operation
- Override system decisions

## Conformity Assessment

### Self-Assessment

For most high-risk AI systems, providers can conduct self-assessment of conformity with requirements. This involves internal control procedures and documentation review.

### Third-Party Assessment

Certain high-risk systems, particularly those used in biometric identification or critical infrastructure, require conformity assessment by notified bodies - independent organizations designated by EU member states.

### CE Marking

AI systems that conform to requirements receive CE marking, indicating compliance and allowing free movement throughout the EU market.

## Provider and User Obligations

### Providers (Developers/Manufacturers)

Providers bear primary responsibility for compliance, including:

- Ensuring conformity with requirements
- Establishing quality management systems
- Maintaining technical documentation
- Implementing post-market monitoring
- Reporting serious incidents and malfunctions

### Users (Deployers)

Organizations deploying high-risk AI systems must:

- Use systems according to instructions
- Ensure human oversight
- Monitor system operation
- Report serious incidents
- Maintain logs generated by the system

### Importers and Distributors

Those bringing AI systems to EU markets or making them available also have compliance obligations, including verifying conformity documentation and ensuring systems bear required CE marking and identification.

## General Purpose AI Models

### Standard Requirements

General purpose AI models (GPAIs), such as large language models, face specific requirements including:

- Technical documentation provision
- Information for downstream providers
- Copyright compliance for training data
- Publicly available summary of training content

### Systemic Risk Models

GPAIs with systemic risk (those trained with computing power exceeding 10^25 FLOPs) face additional obligations:

- Model evaluation and adversarial testing
- Systemic risk assessment and mitigation
- Incident tracking and reporting
- Cybersecurity protection
- Energy efficiency reporting

## Enforcement and Penalties

### National Authorities

Each member state designates competent authorities to supervise AI Act implementation. These authorities have investigation powers, can request information, and access datasets and source code.

### Penalties

Non-compliance can result in administrative fines up to:

- €35 million or 7% of worldwide annual turnover for prohibited AI practices
- €15 million or 3% of turnover for violations of core obligations
- €7.5 million or 1.5% of turnover for providing incorrect information

These penalties are designed to be effective, proportionate, and dissuasive, particularly for large technology companies.

## Innovation Measures

### Regulatory Sandboxes

The AI Act encourages member states to establish regulatory sandboxes - controlled environments where innovative AI systems can be developed and tested under regulatory supervision before full market release.

### SME Support

Small and medium-sized enterprises and startups receive special consideration, with priority access to sandboxes and reduced documentation burdens where appropriate.

## Timeline

The AI Act follows a staggered implementation timeline:

- **6 months**: Prohibited practices ban takes effect
- **12 months**: General purpose AI rules apply
- **24 months**: High-risk systems must comply (36 months for certain sectors)
- **36 months**: Full implementation across all provisions

## Conclusion

The EU AI Act establishes comprehensive regulation while attempting to maintain Europe's competitiveness in AI development. Its risk-based approach targets regulatory attention where it matters most - high-risk applications - while leaving low-risk innovation relatively unburdened. As the first major AI legislation, the Act will likely influence regulation worldwide. Organizations must begin compliance preparation now, as deadlines approach quickly and requirements are substantial. Understanding the AI Act is essential for anyone working with artificial intelligence in or for the European market.

---

**Key Vocabulary:**
- AI Act: Loi sur l'IA
- Risk-based approach: approche basée sur les risques
- High-risk system: système à haut risque
- Conformity assessment: évaluation de la conformité
- CE marking: marquage CE
- Provider: fournisseur/développeur
- Deployer: déployeur/utilisateur
- Regulatory sandbox: bac à sable réglementaire

